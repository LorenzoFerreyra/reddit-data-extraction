{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2025-1 Taller de investigación IV (text-mining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estudiante: Ferreyra, Lorenzo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta notebok se usa la librería [praw](https://praw.readthedocs.io/en/latest/) para extraer comentarios de un subreddit de Reddit mediante la API de Reddit. Anteriormente, se había propuesto una librería de R para extraer tweets de X, pero se encontraron dificultades técnicas a partir de un cambio que hizo Google en su navegador, específicamente en el modo headless empleado en Selenium.\n",
    "El objetivo con el que se genera esta fuente de datos es analizar qué piensan los desarolladores y personal de IT sobre la inteligencia artificial generativa, los grandes modelos de lenguaje y sus productos derivados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cómo accedo a la API de Reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para acceder a la API de Reddit necesitás un Client ID y un Client Secret. Para obtener estos datos, seguí las instrucciones en la sección **First Steps** [acá](https://github.com/reddit-archive/reddit/wiki/OAuth2-Quick-Start-Example). Antes de seguir los pasos, debés crear una cuenta en Reddit, iniciar sesión con ella y luego generar una app en la sección Developers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tengas las credenciales necesarias, lo más recomendable es guardarlas en un archivo .json para mantenerlas seguras. La estructura del archivo debe ser la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "{\"username\":YourUsername, \n",
    " \"password\": YourPassword, \n",
    " \"client_id\":YourClientID, \n",
    " \"client_secret\":YourClientSecret}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En adelante, se asume que esta información está guardada en un archivo llamado `reddit_credentials.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creación de una instancia de Reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer uso de la API, debe crearse una instancia autorizada de `reddit` enviando las credenciales (almacenadas en `reddit_credentials.json`) hacia la clase Reddit de la librería praw. Como las credenciales están originalmente en un json, una vez se carga el archivo, se lo trata como un diccionario de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import praw\n",
    "import json \n",
    "\n",
    "with open('reddit_credentials.json') as fin:\n",
    "    creds = json.load(fin)\n",
    "reddit = praw.Reddit(user_agent='Comment Extraction (by /u/{0})'.format(creds['username']),\n",
    "                     client_id=creds['client_id'], client_secret=creds['client_secret'],\n",
    "                     username=creds['username'], password=creds['password'])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acceder al Subreddit de nuestra preferencia "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se puede crear una instancia del `subreddit` que nos interese eligiendo su nombre real como argumento del método subreddit de nuestra instancia de `reddit`. Como me interesa conocer los comentarios y lo que piensan los desarrolladores y el personal IT en general, elijo el subreddit 'devsarg' que es uno de los más populares en Argentina, y de los más activos también en países limítrofes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "subreddit = reddit.subreddit('devsarg')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar los comentarios que nos interesan dentro de ese subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este bloque de código lo que hace es una especie de \"barrido\" dentro del subreddit r/devsarg, que es una comunidad de desarrolladores de Argentina. La idea es recolectar qué se está diciendo sobre temas relacionados con inteligencia artificial generativa.\n",
    "\n",
    "Para eso, se arma una búsqueda (una \"query\") con palabras clave como:\n",
    "* gpt\n",
    "* ia\n",
    "* chatgpt\n",
    "* ia generativa\n",
    "* vibe coding\n",
    "* cursor\n",
    "* llms\n",
    "\n",
    "Estas palabras están relacionadas con herramientas, tecnologías y conceptos que suelen aparecer en conversaciones sobre IA y programación.\n",
    "\n",
    "El código va recorriendo los últimos 20 posts que coincidan con esas palabras y, por cada uno, guarda la información más importante (como el título, el link, la cantidad de votos, etc.) en un archivo llamado devsarg_search_results.json.\n",
    "\n",
    "Ese archivo después se puede usar para analizar las publicaciones, ver qué temas aparecen más, cómo reaccionan los usuarios, o incluso entrenar algún modelo si quisieras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "query = \"gpt OR ia OR chatgpt OR ia generativa OR vibe coding OR cursor OR llms\"\n",
    "\n",
    "with open('devsarg_search_results.json', 'w') as fout:\n",
    "    for submission in subreddit.search(query, sort=\"new\", limit=20):\n",
    "        thread = get_metadata(submission)\n",
    "        json.dump(thread, fout)\n",
    "        fout.write('\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La metadata que se puede extraer de un subreddit y sus comentarios es muy amplia, entonces achicamos el alcance a solo algunas de las opciones disponibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_metadata(submission):\n",
    "\n",
    "    thread={}\n",
    "    thread[\"title\"]=submission.title\n",
    "    thread[\"score\"]=submission.score\n",
    "    thread[\"id\"]=submission.id\n",
    "    thread[\"url\"]=submission.url\n",
    "    thread[\"comms_num\"]=submission.num_comments\n",
    "    thread[\"created\"]=submission.created\n",
    "    thread[\"body\"]=submission.selftext\n",
    "\n",
    "    return thread\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función va a devolver un diccionario que contiene metadatos sobre cada hilo (post).\n",
    "\n",
    "Ahora podemos recorrer los 20 hilos más nuevos, obtener los metadatos de cada uno y guardar los resultados en un archivo llamado devsarg.json."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "with open('devsarg.json', 'w') as fout:\n",
    "    for submission in subreddit.search(query, sort=\"new\", limit=20):\n",
    "        thread = get_metadata(submission)\n",
    "        json.dump(thread, fout)\n",
    "        fout.write('\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraer comentarios de los posts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos iterar sobre las `submissions` (publicaciones) dentro de un subreddit y obtener metadatos de cada una.\n",
    "\n",
    "Para obtener los comentarios de cada `submission`, podemos usar el atributo `comments`. La estructura de los comentarios en un hilo de subreddit es similar a un árbol: un comentario principal puede tener muchas respuestas, y esas respuestas pueden tener otras respuestas. Por eso, necesitamos recorrer ese \"árbol de comentarios\" para obtenerlos todos.\n",
    "\n",
    "Recorrer el árbol es fácil gracias al objeto `CommentForest` de `praw`. Para más detalles, podés ver este [ejemplo](https://praw.readthedocs.io/en/latest/tutorials/comments.html#extracting-comments) en la documentación oficial de `praw`.\n",
    "\n",
    "Si mirás cómo está estructurado un hilo en devsarg (o en cualquier otro subreddit), vas a notar que para ver todos los comentarios tenés que hacer clic en '1 more comment', '21 more comments', etc.\n",
    "\n",
    "Un punto importante a tener en cuenta es que, para obtener *todos* los comentarios de un hilo, necesitamos realizar una acción similar a esa. En `praw`, esto se puede lograr usando el método `replace_more`, que forma parte de `CommentForest`.\n",
    "\n",
    "En concreto, para obtener todos los comentarios, podemos usar el atributo `comments` sobre cada `submission`, junto con el método `replace_more` y un límite de `None`. Esto solo se hace una vez, y luego ya se puede iterar sobre la lista de todos los comentarios y extraer los datos que necesitemos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_comments(submission):\n",
    "\n",
    "    comments=[]\n",
    "\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments.list():\n",
    "        data={}\n",
    "        data['body']=comment.body\n",
    "        data['id']=comment.fullname\n",
    "\n",
    "        try:\n",
    "            data['author']=comment.author.name\n",
    "\n",
    "        except AttributeError:\n",
    "            data['author']=comment.author\n",
    "\n",
    "        data['time']=comment.created_utc\n",
    "        data['parent']=comment.parent_id\n",
    "\n",
    "        comments.append(data)\n",
    "\n",
    "    return comments\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puesta en práctica del código para generar la fuente de datos requerida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import json \n",
    "\n",
    "def get_comments(submission):\n",
    "\n",
    "    comments=[]\n",
    "\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    for comment in submission.comments.list():\n",
    "        data={}\n",
    "        data['body']=comment.body\n",
    "        data['id']=comment.fullname\n",
    "\n",
    "        try:\n",
    "            data['author']=comment.author.name\n",
    "\n",
    "        except AttributeError:\n",
    "            data['author']=comment.author\n",
    "\n",
    "        data['time']=comment.created_utc\n",
    "        data['parent']=comment.parent_id\n",
    "\n",
    "        comments.append(data)\n",
    "\n",
    "    return comments\n",
    "\n",
    "\n",
    "def get_metadata(submission):\n",
    "\n",
    "    thread={}\n",
    "    thread[\"title\"]=submission.title\n",
    "    thread[\"score\"]=submission.score\n",
    "    thread[\"id\"]=submission.id\n",
    "    thread[\"url\"]=submission.url\n",
    "    thread[\"comms_num\"]=submission.num_comments\n",
    "    thread[\"created\"]=submission.created\n",
    "    thread[\"body\"]=submission.selftext\n",
    "    \n",
    "    thread['posts']= get_comments(submission)\n",
    "\n",
    "    return thread\n",
    "\n",
    "\n",
    "\n",
    "with open('reddit_credentials.json') as fin:\n",
    "    \n",
    "    creds = json.load(fin)\n",
    "    \n",
    "\n",
    "reddit = praw.Reddit(user_agent='Comment Extraction (by /u/{0})'.format(creds['username']),\n",
    "                     client_id=creds['client_id'], client_secret=creds['client_secret'],\n",
    "                     username=creds['username'], password=creds['password'])\n",
    "\n",
    "\n",
    "subreddit = reddit.subreddit('devsarg')\n",
    "query = \"gpt OR ia OR chatgpt OR ia generativa OR vibe coding OR cursor OR llms\"\n",
    "\n",
    "\n",
    "with open('devsarg.json', 'w') as fout:\n",
    "    for submission in subreddit.search(query, sort=\"new\", limit=20):\n",
    "        thread = get_metadata(submission)\n",
    "        json.dump(thread, fout)\n",
    "        fout.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
