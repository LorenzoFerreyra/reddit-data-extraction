---
title: "Trabajo de Taller de investigación: text mining"
author: "Lorenzo Ferreyra"
format: 
  html:
    self-contained: true
editor: visual
toc: true
toc-location: body
toc-title: "Contenido"
number-sections: true
---

## Librerías

Importamos las librerías necesarias.

```{r}
#| echo: false
suppressWarnings(suppressPackageStartupMessages({
  library(readxl)
  library(dplyr)
  library(stringr)
  library(ggplot2)
  library(knitr)
  library(tidytext)
  library(stopwords)
  library(wordcloud2)
  library(syuzhet)
  library(tidyr)
  library(udpipe)
  library(tm)
  library(reshape2)
  library(topicmodels)
}))
```

## Carga de datos

Se leen los archivos de Excel. En el paso anterior de transformación, se dividió el archivo .json extraído de Reddit en dos entidades: comentarios y publicaciones, para mantener una estructura relacional y que los comentarios no pierdan los metadatos de las publicaciones asociadas.

```{r}
comments <- read_excel("output_files/comments.xlsx")
posts <- read_excel("output_files/posts.xlsx")
```

Se obtiene un vistazo preliminar de los primeros registros de los conjuntos de datos para verificar que la lectura del archivo fue exitosa y entender la estructura de las variables antes de iniciar el análisis como tal.

### Estructura de comentarios

```{r}
head(comments, 5) %>% 
  kable()
```

### Estructura de publicaciones

```{r}
head(posts, 5) %>% 
  kable()
```

## Preprocesamiento de datos

Se limpia el texto de los comentarios; se pasa todo a minúsculas, se eliminan links, símbolos irrelevantes, etc.

```{r}
comments_clean <- comments %>%
  mutate(body = str_to_lower(body)) %>%
  mutate(body = str_remove_all(body, "http\\S+|www\\S+")) %>%
  mutate(body = str_remove_all(body, "[^a-záéíóúüñ\\s]")) %>%
  mutate(body = str_squish(body))
```

Como los títulos y el cuerpo de las publicaciones también tienen información muy relevante, se hará una combinación de ambos dataframes, con el mismo procesamiento.

```{r}
posts_clean <- posts %>%
  mutate(body = str_to_lower(body)) %>%
  mutate(body = str_remove_all(body, "http\\S+|www\\S+")) %>%
  mutate(body = str_remove_all(body, "[^a-záéíóúüñ\\s]")) %>%
  mutate(body = str_squish(body))

```

El resultado del preprocesamiento son los siguientes dataframes. Publicaciones:

```{r}
head(posts_clean, 3) %>% 
  kable()
```

Comentarios:

```{r}
head(comments_clean, 5) %>% 
  kable()
```

### Lematización y tokenización

Se lematizan, tokenizan y combinan ambos dataframes con rbind.

```{r}
#modelo_ud <- udpipe_download_model(language = "spanish", model_dir = "models")
modelo <- udpipe_load_model("models/spanish-gsd-ud-2.5-191206.udpipe")
anotados_comentarios <- udpipe_annotate(modelo, x = comments_clean$body)
anotados_comentarios <- as.data.frame(anotados_comentarios)
anotados_comentarios$origen <- "comentario"
anotados_posts <- udpipe_annotate(modelo, x = posts_clean$body)
anotados_posts <- as.data.frame(anotados_posts)
anotados_posts$origen <- "post"
tokens_combinados <- bind_rows(anotados_comentarios, anotados_posts)


```

Observación del dataframe luego del procesamiento de datos y la lematización (que incluye el tokenizado).

```{r}

head(tokens_combinados %>% select(token, lemma, upos, origen), 10) %>% 
  kable()
```

### Eliminación de stopwords

```{r}

stopwords_es <- tibble(palabra = stopwords("es"))
```

### Personalización de las stopwords

Dado que las stopwords que nos ofrece la librería stopwords para la lengua española no es exhaustiva, se la personaliza para agregar unidades relevantes para este caso. Si bien las stopwords suelen ser mayormente las preposiciones, se agregan verbos en infinitivo porque no aportan al análisis.

```{r}
mis_stopwords <- tibble(lemma = c("si", "mas", "ahora", "menos", "solo", "vos",
"mismo", "mejor", "sino", "q","así", "ser", "hacer",  "tener", "haber", "poder", "ir", "decir", "usar", "saber", "dar", "pasar", "querer", "ver", "creer","removed"))
stopwords_es <- tibble(lemma = stopwords("es")) %>%
  bind_rows(mis_stopwords)
tokens_combinados <- tokens_combinados %>%
  filter(!is.na(lemma)) %>%
  anti_join(stopwords_es, by = "lemma")
```

## Análisis de frecuencia de palabras

```{r}
frecuencias <- tokens_combinados %>%
  count(lemma, sort = TRUE)

head(frecuencias, 20) %>%
  ggplot(aes(x = reorder(lemma, n), y = n)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Palabras más frecuentes en los comentarios", x = "", y = "Frecuencia")

```

```{r}
wordcloud2(data = frecuencias, size = 1.5, color = 'random-light', backgroundColor = "black")

```

Palabras como ia, código, gente, programadores y trabajo, además de años, demuestran que en el conjunto de datos se encuentran discusiones relevantes no solo sobre la inteligencia artificial generativa como tal, sino sobre el futuro del trabajo y la productividad.

### Modelado de tópicos con LDA

```{r}
dtm <- tokens_combinados %>%  
  count(doc_id, lemma) %>%  
  cast_dtm(document = doc_id, term = lemma, value = n)
lda_model <- LDA(dtm, k = 3, control = list(seed = 1234))
```

A continuación, se extraen las palabras más representativas por tema y se calcula la probabilidad de cada palabra en cada tópico. Luego, se agrupa por tópico y se eligen las 10 palabras más representativas (con mayor beta), ya que las palabras con mayor beta para cada tópico son las que mejor definen ese tema.

```{r}
topics <- tidy(lda_model, matrix = "beta") %>%
  group_by(topic) %>%
  top_n(10, beta) %>%
  arrange(topic, -beta)
```

Aquí se agrupan las palabras por tópico (una faceta por cada tema) y se muestra qué tan importante (qué tan alta es beta) es cada término para ese tópico.

```{r}
ggplot(topics, aes(x = reorder_within(term, beta, topic),
                   y = beta, fill = factor(topic))) +   geom_col(show.legend = FALSE) +   facet_wrap(~ topic, scales = "free") +   coord_flip() +   scale_x_reordered() +   labs(title = "Tópicos identificados por LDA", x = "Términos", y = "Importancia")
```

Con estos tres grandes tópicos obtenidos mediante LDA, se observa una orientación pragmática en las conversaciones de la comunidad IT sobre la inteligencia artificial generativa. Entre los resultados se destacan el interés por su aplicación concreta en el desarrollo y la programación (tópico 2), así como su impacto en el ámbito laboral y profesional (tópico 1). El tópico 3, más vinculado a aspectos sociales, muestra que también se tienen discusiones sobre dinámicas colectivas y cuestiones socioeconómicas, como el papel de los sindicatos. Esto complementa las preocupaciones sobre el trabajo ya observadas y refuerza las hipótesis de un enfoque funcional y de alerta ante las transformaciones laborales. La falta de un tópico enfocado exclusivamente en aspectos éticos sugiere que, en comparación con los temas técnicos y ocupacionales, las inquietudes éticas ocupan un lugar más bien subalterno.

## Análisis de sentimientos

Se utiliza el léxico NRC adaptado al español, el cual clasifica las palabras en categorías de emociones básicas (como *joy*, *fear*, *anger*, *trust*, etc.) y también según polaridad (*positive* o *negative*).

```{r}
sentimientos <- get_nrc_sentiment(tokens_combinados$lemma, language = "spanish")

```

```{r}
sentimientos$palabra <- tokens_combinados$lemma

```

```{r}
sentimientos_totales <- sentimientos %>%
  select(-palabra) %>%  
  summarise(across(everything(), sum)) %>%  
  pivot_longer(cols = everything(), names_to = "sentimiento", values_to = "frecuencia") %>%
  arrange(desc(frecuencia))
ggplot(sentimientos_totales, aes(x = reorder(sentimiento, frecuencia), y = frecuencia, fill = sentimiento)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(
    title = "Distribución de sentimientos en los comentarios",
    x = "Sentimiento",
    y = "Frecuencia"
  )
```

A partir del análisis de los comentarios y publicaciones combinados, se observa una predominancia de sentimientos positivos, seguidos por negativos, y en menor medida, emociones como *trust*, *anticipation*, *sadness* y *fear*. Esta distribución posibilta la hipótesis de una actitud pragmática y funcional por parte de los profesionales IT frente a la inteligencia artificial generativa, con una valoración positiva de su potencial productivo, aunque sin dejar de lado preocupaciones técnicas o éticas.

Asimismo, el hecho de que las emociones negativas no sean dominantes, pero sí estén presentes de forma significativa (*fear*, *sadness*, *anger*), permite identificar tensiones latentes respecto al impacto de estas tecnologías, especialmente cuando se piensa en la calidad de los resultados y el futuro del trabajo.

```{r}
polaridad <- sentimientos_totales %>%
  filter(sentimiento %in% c("positive", "negative"))

ggplot(polaridad, aes(x = sentimiento, y = frecuencia, fill = sentimiento)) +
  geom_col(show.legend = FALSE) +
  labs(title = "Polaridad de los sentimientos", x = "Polaridad", y = "Frecuencia")

```

## Interpretación de resultados y discusión

### ¿Qué temas o preocupaciones se mencionan con mayor frecuencia?

Para contestar esta pregunta, se identifican los temas más mencionados en los textos. Para ello, se crean columnas binarias que detectan si en cada comentario o publicación aparecen palabras clave asociadas a productividad, empleo, errores técnicos o cuestiones éticas. Se cuenta cuántas veces se menciona cada tema y se visualiza en un gráfico. Esto permite observar qué preocupaciones son más frecuentes en el discurso sobre IA generativa entre profesionales IT.

```{r}
tokens_combinados <- tokens_combinados %>%
  mutate(
    menciona_productividad = if_else(str_detect(lemma, 
      "automatizar|automatización|ayuda|mejora|productividad|eficiencia|rápido|velocidad|optimizar|optimización|rendimiento|agilizar|facilitar|acelerar|aumentar"), 1, 0),
    
    menciona_empleo = if_else(str_detect(lemma, 
      "desempleo|reemplazo|trabajo|empleo|ocupación|puesto|laboral|desarrollador|profesión|oficio|recursos|sustituir|desplazar|perder"), 1, 0),
    
    menciona_errores = if_else(str_detect(lemma, 
      "alucinar|alucinación|error|equivocar|confundir|malo|incorrecto|fallo|problema|falla|defecto|limitación|inexacto|bug"), 1, 0),
    
    menciona_etica = if_else(str_detect(lemma, 
      "sesgo|ética|desinformación|manipular|engaño|falsedad|engañoso|responsabilidad|transparencia|discriminación|prejuicio|moral|control|censura|justicia|privacidad"), 1, 0)
  )
menciones_totales <- tokens_combinados %>%
  summarise(
    productividad = sum(menciona_productividad),
    empleo = sum(menciona_empleo),
    errores = sum(menciona_errores),
    etica = sum(menciona_etica)
  ) %>%
  pivot_longer(cols = everything(), names_to = "categoria", values_to = "frecuencia")

ggplot(menciones_totales, aes(x = reorder(categoria, frecuencia), y = frecuencia, fill = categoria)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  labs(
    title = "Frecuencia de menciones por tema clave",
    x = "Categoría",
    y = "Frecuencia"
  ) +
  scale_fill_brewer(palette = "Set2")

```

Puede observarse un enfoque pragmático en los usuarios del subreddit acerca del impacto directo de la tecnología. Los temas de 'empleo' (más de 150 menciones) y 'productividad' (más de 100 menciones) son los más frecuentes, lo que demuestra la importancia de estos tópicos. Las menciones de 'errores' también son significativas, mientras que la 'ética' es el tema menos discutido.

Así, , los profesionales IT que participan en estas discusiones sobre IA generativa parecen tener una mentalidad muy pragmática, orientada a la utilidad y profundamente consciente de las implicaciones laborales y los desafíos técnicos de esta tecnología. Las consideraciones éticas están presentes, pero ocupan un segundo plano no significativo en comparación con estas preocupaciones más directas y personales.

### ¿Qué actitudes predominan: entusiasmo, escepticismo, temor, indiferencia?

Para contestar esta pregunta, se agrupan las emociones en tres grandes actitudes frente a la inteligencia artificial generativa: entusiasmo, temor y escepticismo. La categoría de entusiasmo incluye emociones como alegría, confianza y anticipación, además de la polaridad positiva, y refleja una actitud optimista respecto al potencial productivo de estas tecnologías. Por otro lado, las emociones vinculadas al temor, como miedo y tristeza, expresan inquietudes relacionadas con el impacto de la IA en el trabajo, la precisión de sus respuestas o la incertidumbre general frente a su avance.

El escepticismo, por otro lado, se asocia con emociones como enojo, disgusto y la polaridad negativa, y suele expresar una postura crítica o de rechazo, especialmente frente a limitaciones técnicas o posibles consecuencias sociales.

```{r}
actitudes <- sentimientos_totales %>%
mutate(
actitud = case_when(
sentimiento %in% c("joy", "trust", "positive", "anticipation") ~ "entusiasmo",
sentimiento %in% c("fear", "sadness") ~ "temor",
      sentimiento %in% c("anger", "disgust", "negative") ~ "escepticismo",
TRUE ~ "otro"
)
) %>%
group_by(actitud) %>%
summarise(frecuencia = sum(frecuencia))

ggplot(actitudes, aes(x = actitud, y = frecuencia, fill = actitud)) +
geom_col(show.legend = FALSE) +
labs(title = "Actitudes predominantes en los comentarios", x = "", y = "Frecuencia")
```

La distribución observada muestra un predominio de actitudes entusiastas, seguidas por una presencia significativa tanto de escepticismo seguidamente de temor, por lo que puede considerarse una comunidad que valora el potencial de la IA pero que no deja de señalar sus riesgos y desafíos.
